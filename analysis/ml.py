import jsonimport pandas as pdimport numpy as npfrom scipy.stats import chi2from sklearn.mixture import GaussianMixturefrom sklearn.svm import OneClassSVMfrom scipy.stats import normfrom sklearn.decomposition import PCAclass ml:        def  __init__(self, screen):        # initialize matrices for start, end, error        self.start = []        self.end = []        self.error = []                # fill matrices for start, end, error        self.parseJSON(screen)        self.df = pd.DataFrame({"start": self.start, "end": self.end})        def parseJSON(self, screen):        """        Parameters        ----------        screen : JSON file with rows including key value,         start time of pressing the key,         end time of pressing the key.        Returns        -------        n/a.        """        with open(screen, "r") as json_file:            data = json.load(json_file)                b = 0        for row in data:            if row['key'] == 'b':                b += 1                self.error[b*-1] += 1            else:                if b == 0:                    self.start.append(row['start'])                    self.end.append(row['end'])                else:                    self.start[b*-1] = row['start']                    self.start[b*-2] = row['end']                        def supervised_ml(self):        pass        def unsupervised_ml(self):        last_row = self.df.iloc[-1].squeeze()        self.one_class_SVM(last_row)        self.PCA(last_row)        self.mahalanobis_dist(last_row)        self.GMM(last_row)    def one_class_SVM(self, vector):        # Fit a One-Class SVM model        svm_model = OneClassSVM(nu=0.05)  # Adjust the 'nu' hyperparameter as needed        svm_model.fit(self.df)        # Calculate the decision function score for the new data vector        distance_score = svm_model.decision_function([vector])[0]        outlier_probability = norm.cdf(distance_score)        print(f"Outlier Probability: {outlier_probability}")    def PCA(self, vector):        # Fit a PCA model to your data        n_components = 2  # Adjust the number of principal components as needed        pca_model = PCA(n_components=n_components)        pca_model.fit(self.df)        # Project the new data vector onto the principal components        new_data_projected = pca_model.transform([vector])        # Reconstruct the data vector using the principal components        reconstructed_data = pca_model.inverse_transform(new_data_projected)        # Calculate the reconstruction error for the new data vector        reconstruction_error = np.mean(np.square(vector - reconstructed_data))        # Convert the reconstruction error to an outlier probability        # You can adjust this conversion based on your data distribution and needs        outlier_probability = 1.0 - np.exp(-reconstruction_error)        print(f"Outlier Probability: {outlier_probability}")    def mahalanobis_dist(self, vector):        # Calculate the mean and covariance matrix of the data vectors        mean_vector = np.mean(self.df, axis=0)        cov_matrix = np.cov(self.df, rowvar=False)        # Calculate the Mahalanobis distance for the new data vector        diff_vector = vector - mean_vector        mahalanobis_distance = np.sqrt(np.dot(np.dot(diff_vector, np.linalg.inv(cov_matrix)), diff_vector))        # Degrees of freedom for the chi-squared distribution        df_chi2 = len(self.df.columns)        # Convert Mahalanobis distance to an outlier probability        outlier_probability = 1.0 - chi2.cdf(mahalanobis_distance ** 2, df_chi2)        print(f"Outlier Probability: {outlier_probability}")    def GMM(self, vector):        gmm = GaussianMixture(n_components=2)  # You can adjust the number of components        gmm.fit(self.df)        # Calculate the log probability density for the new data vector        log_prob = gmm.score_samples([vector])        # Calculate the outlier probability (normalized percentile rank)        outlier_prob = len(log_prob[log_prob <= log_prob[0]]) / len(log_prob)        print(f"Outlier Probability: {outlier_prob}")